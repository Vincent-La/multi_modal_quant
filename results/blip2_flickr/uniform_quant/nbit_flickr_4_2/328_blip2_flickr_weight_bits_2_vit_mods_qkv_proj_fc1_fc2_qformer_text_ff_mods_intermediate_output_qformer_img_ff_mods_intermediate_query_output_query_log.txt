WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0, world 8): env://
| distributed init (rank 6, world 8): env://
| distributed init (rank 1, world 8): env://
| distributed init (rank 7, world 8): env://
| distributed init (rank 3, world 8): env://
| distributed init (rank 4, world 8): env://
| distributed init (rank 2, world 8): env://
| distributed init (rank 5, world 8): env://
2024-07-11 15:07:25,084 [INFO] 
=====  Running Parameters    =====
CACHE_ROOT:/fs/cfar-projects/low-bit-vision/lavis_cache
STORAGE_PATH:/fs/cfar-projects/low-bit-vision/lavis_cache/flickr30k/annotations/train.json
2024-07-11 15:07:25,104 [INFO] {
    "batch_size_eval": 32,
    "batch_size_train": 16,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": true,
    "gpu": 0,
    "k_test": 128,
    "num_workers": 4,
    "output_dir": "output/BLIP2/Retrieval_Flickr30k",
    "rank": 0,
    "seed": 42,
    "task": "retrieval",
    "test_splits": [
        "test"
    ],
    "use_dist_eval_sampler": false,
    "world_size": 8
}
2024-07-11 15:07:25,104 [INFO] 
======  Dataset Attributes  ======
2024-07-11 15:07:25,104 [INFO] 
======== flickr30k =======
2024-07-11 15:07:25,104 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "storage": "flickr30k/annotations/test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/flickr30k_test.json"
            },
            "train": {
                "storage": "flickr30k/annotations/train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/flickr30k_train.json"
            },
            "val": {
                "storage": "flickr30k/annotations/val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/flickr30k_val.json"
            }
        },
        "images": {
            "storage": "flickr30k/images"
        }
    },
    "data_type": "images",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        }
    },
    "vis_processor": {
        "eval": {
            "image_size": 364,
            "name": "blip_image_eval"
        }
    }
}
2024-07-11 15:07:25,104 [INFO] 
======  Model Attributes  ======
2024-07-11 15:07:25,105 [INFO] {
    "arch": "blip2",
    "drop_path_rate": 0,
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_finetune_coco.pth",
    "freeze_vit": false,
    "image_size": 364,
    "load_finetuned": true,
    "model_type": "coco",
    "num_query_token": 32,
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained.pth",
    "use_grad_checkpoint": false,
    "vit_precision": "fp32"
}
Using downloaded and verified file: /fs/cfar-projects/low-bit-vision/lavis_cache/flickr30k/annotations/train.json
STORAGE_PATH:/fs/cfar-projects/low-bit-vision/lavis_cache/flickr30k/annotations/val.json
Using downloaded and verified file: /fs/cfar-projects/low-bit-vision/lavis_cache/flickr30k/annotations/val.json
STORAGE_PATH:/fs/cfar-projects/low-bit-vision/lavis_cache/flickr30k/annotations/test.json
Using downloaded and verified file: /fs/cfar-projects/low-bit-vision/lavis_cache/flickr30k/annotations/test.json
2024-07-11 15:07:25,213 [INFO] Building datasets...
2024-07-11 15:07:27,031 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-11 15:07:27,033 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-11 15:07:27,034 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-11 15:07:27,036 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-11 15:07:27,056 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-11 15:07:27,057 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-11 15:07:27,061 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-11 15:07:27,066 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

MODEL_NAME: eva_clip_g
Position interpolate from 16x16 to 26x26
2024-07-11 15:09:58,789 [INFO] Missing keys []
2024-07-11 15:09:58,789 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_finetune_coco.pth
2024-07-11 15:10:49,726 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-11 15:10:49,730 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

Blip2Qformer(
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): NBitLinearDynamic(in_features=1408, out_features=4224, bias=False | w=2, a=32)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): NBitLinearDynamic(in_features=1408, out_features=1408, bias=True | w=2, a=32)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): NBitLinearDynamic(in_features=1408, out_features=6144, bias=True | w=2, a=32)
          (act): GELU(approximate='none')
          (fc2): NBitLinearDynamic(in_features=6144, out_features=1408, bias=True | w=2, a=32)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (Qformer): BertLMHeadModel(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30523, 768)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
2024-07-11 15:10:49,760 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=1408, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (key): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (value): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): NBitLinearDynamic(in_features=768, out_features=768, bias=True | w=2, a=32)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (intermediate_query): BertIntermediate(
              (dense): NBitLinearDynamic(in_features=768, out_features=3072, bias=True | w=2, a=32)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): NBitLinearDynamic(in_features=3072, out_features=768, bias=True | w=2, a=32)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (cls): BertOnlyMLMHead(
      (predictions): BertLMPredictionHead(
        (transform): BertPredictionHeadTransform(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (transform_act_fn): GELUActivation()
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (decoder): Linear(in_features=768, out_features=30523, bias=True)
      )
    )
  )
  (vision_proj): Linear(in_features=768, out_features=256, bias=True)
  (text_proj): Linear(in_features=768, out_features=256, bias=True)
  (itm_head): Linear(in_features=768, out_features=2, bias=True)
)
[Model Size]: 484.186164
2024-07-11 15:10:49,770 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-11 15:10:49,791 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2024-07-11 15:10:49,791 [INFO] Loaded 145000 records for train split from the dataset.
2024-07-11 15:10:49,791 [INFO] Loaded 1014 records for val split from the dataset.
2024-07-11 15:10:49,791 [INFO] Loaded 1000 records for test split from the dataset.
2024-07-11 15:10:49,791 [INFO] Empty train splits.
2024-07-11 15:10:49,791 [INFO] Empty train splits.
2024-07-11 15:10:49,791 [INFO] Empty train splits.
2024-07-11 15:10:49,792 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-11 15:10:49,795 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-11 15:10:49,933 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-11 15:10:49,961 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-11 15:10:54,478 [INFO] Computing features for evaluation...
Evaluation:  [  0/126]  eta: 0:03:48    time: 1.8163  data: 0.0003  max mem: 11808
Evaluation:  [ 50/126]  eta: 0:01:35    time: 1.2413  data: 0.0000  max mem: 11808
Evaluation:  [100/126]  eta: 0:00:32    time: 1.2478  data: 0.0000  max mem: 11808
Evaluation:  [125/126]  eta: 0:00:01    time: 1.2449  data: 0.0000  max mem: 11808
Evaluation: Total time: 0:02:37 (1.2473 s / it)
Evaluation:  [  0/626]  eta: 0:17:31    time: 1.6791  data: 0.0008  max mem: 11808
Evaluation:  [ 50/626]  eta: 0:17:34    time: 1.8386  data: 0.0000  max mem: 11808
Evaluation:  [100/626]  eta: 0:16:06    time: 1.8374  data: 0.0000  max mem: 11808
Evaluation:  [150/626]  eta: 0:14:34    time: 1.8372  data: 0.0000  max mem: 11808
Evaluation:  [200/626]  eta: 0:13:02    time: 1.8524  data: 0.0000  max mem: 11808
Evaluation:  [250/626]  eta: 0:11:29    time: 1.7962  data: 0.0000  max mem: 11808
Evaluation:  [300/626]  eta: 0:09:57    time: 1.8451  data: 0.0000  max mem: 11808
Evaluation:  [350/626]  eta: 0:08:26    time: 1.8502  data: 0.0000  max mem: 11808
Evaluation:  [400/626]  eta: 0:06:54    time: 1.8420  data: 0.0000  max mem: 11808
Evaluation:  [450/626]  eta: 0:05:22    time: 1.8177  data: 0.0000  max mem: 11808
Evaluation:  [500/626]  eta: 0:03:51    time: 1.8267  data: 0.0000  max mem: 11808
Evaluation:  [550/626]  eta: 0:02:19    time: 1.8347  data: 0.0000  max mem: 11808
Evaluation:  [600/626]  eta: 0:00:47    time: 1.8324  data: 0.0000  max mem: 11808
Evaluation:  [625/626]  eta: 0:00:01    time: 1.8374  data: 0.0000  max mem: 11808
Evaluation: Total time: 0:19:08 (1.8347 s / it)
2024-07-11 15:36:51,527 [INFO] Evaluation time 0:25:57
2024-07-11 15:36:53,768 [INFO] {'txt_r1': 0.1, 'txt_r5': 0.4, 'txt_r10': 0.9, 'txt_r_mean': 0.4666666666666666, 'img_r1': 0.08, 'img_r5': 0.54, 'img_r10': 1.0, 'img_r_mean': 0.54, 'r_mean': 0.5033333333333333, 'agg_metrics': 0.4666666666666666}
